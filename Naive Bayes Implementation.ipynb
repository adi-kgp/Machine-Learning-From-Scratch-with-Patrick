{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMzOKIcY7/K9rG0XMOnP1o9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Naive Bayes Implementation"],"metadata":{"id":"MBLO42mmr6xf"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Naive Bayes Class Implementation\n","class NaiveBayes:\n","\n","    def fit(self, X, y):\n","        n_samples, n_features = X.shape\n","        self._classes = np.unique(y)\n","        n_classes = len(self._classes)\n","\n","        # init mean, var, priors for each class\n","        self._mean = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._var = np.zeros((n_classes, n_features), dtype=np.float64)\n","        self._priors = np.zeros(n_classes, dtype=np.float64)\n","\n","        for idx, c in enumerate(self._classes):\n","            X_c = X[y == c]\n","            self._mean[idx, :] = X_c.mean(axis=0)\n","            self._var[idx, :] = X_c.var(axis=0)\n","            self._priors[idx] = X_c.shape[0] / float(n_samples)\n","\n","    def predict(self, X):\n","        y_pred = [self._predict(x) for x in X]\n","        return np.array(y_pred)\n","\n","    def _predict(self, x):\n","        posteriors = []\n","\n","        # caluclate posterior probability for each class\n","        for idx, c in enumerate(self._classes):\n","            prior = np.log(self._priors[idx])\n","            class_conditional = np.sum(np.log(self._pdf(idx, x)))\n","            posterior = prior + class_conditional\n","            posteriors.append(posterior)\n","\n","        # return class with highest posterior probability\n","        return self._classes[np.argmax(posteriors)]\n","\n","    def _pdf(self, class_idx, x):\n","        mean = self._mean[class_idx]\n","        var = self._var[class_idx] \n","        numerator = np.exp(-((x - mean)**2) / (2 * var))\n","        denominator = np.sqrt(2* np.pi *var)\n","        return numerator / denominator"],"metadata":{"id":"5j8U5ZymtUsW","executionInfo":{"status":"ok","timestamp":1672567954133,"user_tz":-330,"elapsed":622,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn import datasets\n","import matplotlib.pyplot as plt\n","\n","def accuracy(y_true, y_pred):\n","    accuracy = np.sum(y_true == y_pred) / len(y_true)\n","    return accuracy\n","\n","X, y = datasets.make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=123)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 123)\n","\n","nb = NaiveBayes()\n","nb.fit(X_train, y_train)\n","predictions = nb.predict(X_test)\n","\n","print(\"Naive Bayes Classification accuracy\", accuracy(y_test, predictions))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vRtUh58Vw-JH","executionInfo":{"status":"ok","timestamp":1672567956078,"user_tz":-330,"elapsed":11,"user":{"displayName":"Aditya Sharma","userId":"18274581938771633663"}},"outputId":"348cf4d1-81a7-4fbe-9f9f-190f285f8686"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Naive Bayes Classification accuracy 0.965\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"gV7JykUHx487"},"execution_count":null,"outputs":[]}]}